{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Lambda, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Cargar el DataFrame desde el archivo Parquet utilizando Dask\n",
    "data_dd = dd.read_parquet(r'C:\\Users\\HOME\\OneDrive - Universidad Nacional de Colombia\\maestria_big_data\\clases\\TFM\\codigo_TFM\\data.parquet', engine='pyarrow')\n",
    "\n",
    "# Convertir los datos de Dask a pandas para el preprocesamiento\n",
    "data_pd = data_dd.compute()\n",
    "X = data_pd['susceptibilidad'].values.reshape(-1, 1)\n",
    "y = data_pd['inventario'].values\n",
    "\n",
    "# Liberar memoria\n",
    "del data_dd, data_pd\n",
    "gc.collect()\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para balancear el conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "\n",
    "# Definir la función de activación Kolmogorov\n",
    "def kolmogorov_activation(x):\n",
    "    # Aplicar softplus para manejar adecuadamente los valores\n",
    "    return K.softplus(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar la función de pérdida con pesos de clase\n",
    "class_weights = {0: 1, 1: 10}  # Aumentar el peso para la clase minoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construir y compilar el modelo con regularización y dropout para mayor estabilidad\n",
    "model = Sequential([\n",
    "    Dense(50, activation='relu', input_shape=(1,), kernel_regularizer=l2(0.01)),  # Añadir regularización L2\n",
    "    Dropout(0.5),  # Añadir Dropout para reducir sobreajuste\n",
    "    Dense(50, activation='softplus', kernel_regularizer=l2(0.01)),  # Cambiar activación para mayor estabilidad\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss=BinaryCrossentropy(from_logits=False), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.4217 - loss: 44.1353 - val_accuracy: 0.7384 - val_loss: 0.8796\n",
      "Epoch 2/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.3568 - loss: 13.2339 - val_accuracy: 0.7306 - val_loss: 0.9043\n",
      "Epoch 3/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.3162 - loss: 4.1413 - val_accuracy: 0.2545 - val_loss: 0.9592\n",
      "Epoch 4/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.2766 - loss: 3.1163 - val_accuracy: 0.2545 - val_loss: 1.0342\n",
      "Epoch 5/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.2648 - loss: 2.7063 - val_accuracy: 0.2545 - val_loss: 1.0549\n",
      "Epoch 6/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.2580 - loss: 2.2281 - val_accuracy: 0.2545 - val_loss: 1.1156\n",
      "Epoch 7/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.2623 - loss: 2.1437 - val_accuracy: 0.2545 - val_loss: 1.1436\n",
      "Epoch 8/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.2581 - loss: 2.1411 - val_accuracy: 0.2545 - val_loss: 1.1670\n",
      "Epoch 9/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.2606 - loss: 2.0481 - val_accuracy: 0.2545 - val_loss: 1.1662\n",
      "Epoch 10/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.2488 - loss: 2.0320 - val_accuracy: 0.2545 - val_loss: 1.1741\n",
      "Epoch 11/100\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.2598 - loss: 2.0133 - val_accuracy: 0.2545 - val_loss: 1.2034\n"
     ]
    }
   ],
   "source": [
    "# Configurar EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100, \n",
    "    batch_size=32,  # Incrementar el tamaño del batch\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping], \n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss en el conjunto de prueba: 0.8788866400718689\n",
      "Accuracy en el conjunto de prueba: 0.7432249188423157\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step\n",
      "[[2179   44]\n",
      " [ 714   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.98      0.85      2223\n",
      "         1.0       0.25      0.02      0.04       729\n",
      "\n",
      "    accuracy                           0.74      2952\n",
      "   macro avg       0.50      0.50      0.44      2952\n",
      "weighted avg       0.63      0.74      0.65      2952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Loss en el conjunto de prueba: {test_loss}')\n",
    "print(f'Accuracy en el conjunto de prueba: {test_accuracy}')\n",
    "\n",
    "# Predecir y mostrar métricas adicionales\n",
    "y_test_pred = model.predict(X_test).round()\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
